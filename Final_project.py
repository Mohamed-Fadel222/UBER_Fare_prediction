# -*- coding: utf-8 -*-
"""final1 bestest Bo_fadel_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xbo_tGpyY3LI3NhS8zEFmkpcwPpy97Ae
"""

import pandas as pd
import geopy.distance
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import HuberRegressor
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

data=pd.read_csv('uber.csv')

data.head()

q1=data['fare_amount'].quantile(0.25)
q3=data['fare_amount'].quantile(0.75)
IQR=q3-q1
LB=q1-1.5*IQR
UB=q3+1.5*IQR
data = data[(data['fare_amount']>=LB) & (data['fare_amount']<=UB) ]
data.shape

data.drop(['passenger_count','Unnamed: 0','key'],axis=1,inplace=True)

data.info()

data.isnull().sum()

data=data.dropna()

data=data[~((data['pickup_latitude']==data['dropoff_latitude'])&(data['pickup_longitude']==data['dropoff_longitude']))]
print(f'After dropping the data, the final shape is {data.shape}')

data=data[~(data['fare_amount']<=4.1)]
print(f'After dropping the data, the final shape is {data.shape}')

data = data[(data.pickup_latitude<90) & (data.dropoff_latitude<90) &
        (data.pickup_latitude>-90) & (data.dropoff_latitude>-90) &
        (data.pickup_longitude<180) & (data.dropoff_longitude<180) &
        (data.pickup_longitude>-180) & (data.dropoff_longitude>-180)]

data.pickup_datetime=pd.to_datetime(data.pickup_datetime)

data['year'] = data.pickup_datetime.dt.year
data['month'] = data.pickup_datetime.dt.month
data['weekday'] = data.pickup_datetime.dt.weekday
data['hour'] = data.pickup_datetime.dt.hour

data['Monthly_Quarter'] = data.month.map({1:'Q1',2:'Q1',3:'Q1',4:'Q2',5:'Q2',6:'Q2',7:'Q3',
                                      8:'Q3',9:'Q3',10:'Q4',11:'Q4',12:'Q4'})
data['Hourly_Segments'] = data.hour.map({0:'H1',1:'H1',2:'H1',3:'H1',4:'H2',5:'H2',6:'H2',7:'H2',8:'H3',
                                     9:'H3',10:'H3',11:'H3',12:'H4',13:'H4',14:'H4',15:'H4',16:'H5',
                                     17:'H5',18:'H5',19:'H5',20:'H6',21:'H6',22:'H6',23:'H6'})

data['distance']=[round(geopy.distance.distance((data.pickup_latitude[i], data.pickup_longitude[i]),(data.dropoff_latitude[i], data.dropoff_longitude[i])).m,2) for i in data.index]

data.drop(['pickup_datetime','month', 'hour'], axis=1, inplace=True)

original_data = data.copy(deep=True)

data.head()

q1=data['distance'].quantile(0.25)
q3=data['distance'].quantile(0.75)
IQR=q3-q1
LB=q1-1.5*IQR
UB=q3+1.5*IQR
data = data[(data['distance']>=LB) & (data['distance']<=UB) ]
data.shape

data.describe()

data.duplicated().sum()

data.drop_duplicates(inplace= True)

data.info()

from sklearn.preprocessing import LabelEncoder
LabelEncoder=LabelEncoder()
for column in data.columns:
  if data[column].dtype=='object':
    data[column] = LabelEncoder.fit_transform(data[column].astype(str))

data.info()

scaler = StandardScaler()
features_to_scale = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','distance']
data[features_to_scale] = scaler.fit_transform(data[features_to_scale])

x=data.drop('fare_amount',axis=1)
y=data['fare_amount']

x.head

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

'''
random_forest_model = RandomForestRegressor(n_estimators=100, random_state=52)
random_forest_model.fit(x_train, y_train)
y_pred_rf_train = random_forest_model.predict(x_train)
rf_model_mse_train = mean_squared_error(y_train, y_pred_rf_train)
'''

#y_pred_rf_test = random_forest_model.predict(x_test)
#rf_model_mse_test = mean_squared_error(y_test, y_pred_rf_test)

import xgboost as xgb
xgb_model=xgb.XGBRegressor()
xgb_model.fit(x_train,y_train)
y_pred_xgb_train=xgb_model.predict(x_train)
xgb_model_mse_train=mean_squared_error(y_train,y_pred_xgb_train)

y_pred_xgb_test=xgb_model.predict(x_test)
xgb_model_mse_test=mean_squared_error(y_test,y_pred_xgb_test)


print(f'Mean Squared Error of train(Xgboost Regression): {xgb_model_mse_train}')
print(f'Mean Squared Error of test (Xgboost Regression): {xgb_model_mse_test}')

import pickle

filename = "XGboost.pkl"
pickle.dump(xgb_model, open(filename, "wb"))


data.head(5)



