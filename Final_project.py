# -*- coding: utf-8 -*-
"""final1 bestest Bo_fadel_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xbo_tGpyY3LI3NhS8zEFmkpcwPpy97Ae
"""

import pandas as pd
import geopy.distance
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import HuberRegressor
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.linear_model import ElasticNet
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

data=pd.read_csv('uber.csv')

data.head()

q1=data['fare_amount'].quantile(0.25)
q3=data['fare_amount'].quantile(0.75)
IQR=q3-q1
LB=q1-1.5*IQR
UB=q3+1.5*IQR
data = data[(data['fare_amount']>=LB) & (data['fare_amount']<=UB) ]
data.shape

data.drop(['passenger_count','Unnamed: 0','key'],axis=1,inplace=True)

data.info()

data.isnull().sum()

data=data.dropna()

data=data[~((data['pickup_latitude']==data['dropoff_latitude'])&(data['pickup_longitude']==data['dropoff_longitude']))]
print(f'After dropping the data, the final shape is {data.shape}')

data=data[~(data['fare_amount']<0)]
print(f'After dropping the data, the final shape is {data.shape}')

data = data[(data.pickup_latitude<90) & (data.dropoff_latitude<90) &
        (data.pickup_latitude>-90) & (data.dropoff_latitude>-90) &
        (data.pickup_longitude<180) & (data.dropoff_longitude<180) &
        (data.pickup_longitude>-180) & (data.dropoff_longitude>-180)]

data.pickup_datetime=pd.to_datetime(data.pickup_datetime)

data['year'] = data.pickup_datetime.dt.year
data['month'] = data.pickup_datetime.dt.month
data['weekday'] = data.pickup_datetime.dt.weekday
data['hour'] = data.pickup_datetime.dt.hour


data['distance']=[round(geopy.distance.distance((data.pickup_latitude[i], data.pickup_longitude[i]),(data.dropoff_latitude[i], data.dropoff_longitude[i])).m,2) for i in data.index]

data.drop(['pickup_datetime','month', 'hour'], axis=1, inplace=True)

original_data = data.copy(deep=True)

data.head()

q1=data['distance'].quantile(0.25)
q3=data['distance'].quantile(0.75)
IQR=q3-q1
LB=q1-1.5*IQR
UB=q3+1.5*IQR
data = data[(data['distance']>=LB) & (data['distance']<=UB) ]
data.shape

q1=data['fare_amount'].quantile(0.25)
q3=data['fare_amount'].quantile(0.75)
IQR=q3-q1
LB=q1-1.5*IQR
UB=q3+1.5*IQR
data = data[(data['fare_amount']>=LB) & (data['fare_amount']<=UB) ]
data.shape

data.describe()

data.duplicated().sum()

data.drop_duplicates(inplace= True)

data.info()

from sklearn.preprocessing import LabelEncoder
LabelEncoder=LabelEncoder()
for column in data.columns:
  if data[column].dtype=='object':
    data[column] = LabelEncoder.fit_transform(data[column].astype(str))

data.info()

scaler = StandardScaler()
features_to_scale = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude','distance']
data[features_to_scale] = scaler.fit_transform(data[features_to_scale])

x=data.drop('fare_amount',axis=1)
y=data['fare_amount']

x.head

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

'''
random_forest_model = RandomForestRegressor(n_estimators=100, random_state=52)
random_forest_model.fit(x_train, y_train)
y_pred_rf_train = random_forest_model.predict(x_train)
rf_model_mse_train = mean_squared_error(y_train, y_pred_rf_train)
'''

#y_pred_rf_test = random_forest_model.predict(x_test)
#rf_model_mse_test = mean_squared_error(y_test, y_pred_rf_test)

import xgboost as xgb
xgb_model=xgb.XGBRegressor()
xgb_model.fit(x_train,y_train)
y_pred_xgb_train=xgb_model.predict(x_train)
xgb_model_mse_train=mean_squared_error(y_train,y_pred_xgb_train)

y_pred_xgb_test=xgb_model.predict(x_test)
xgb_model_mse_test=mean_squared_error(y_test,y_pred_xgb_test)


print(f'Mean Squared Error of train(Xgboost Regression): {xgb_model_mse_train}')
print(f'Mean Squared Error of test (Xgboost Regression): {xgb_model_mse_test}')

LR_model = LinearRegression().fit(x_train, y_train)
y_pred_LR = LR_model.predict(x_test)
LR_model_mse = mean_squared_error(y_test, y_pred_LR)
print(f'Mean Squared Error (Linear Regression): {LR_model_mse}')

huber_model = HuberRegressor()
huber_model.fit(x_train, y_train)
y_pred_huber = huber_model.predict(x_test)
huber_model_mse = mean_squared_error(y_test, y_pred_huber)
print(f'Mean Squared Error (Huber Regression): {huber_model_mse}')

ridge_model = Ridge(alpha=1.0)
ridge_model.fit(x_train, y_train)
y_pred_ridge = ridge_model.predict(x_test)
ridge_model_mse = mean_squared_error(y_test, y_pred_ridge)
print(f'Mean Squared Error (Ridge Regression): {ridge_model_mse}')

random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)
random_forest_model.fit(x_train, y_train)
y_pred_rf = random_forest_model.predict(x_test)
rf_model_mse = mean_squared_error(y_test, y_pred_rf)
print(f'Mean Squared Error (Random Forest): {rf_model_mse}')

lasso_model = Lasso(alpha=1.0)
lasso_model.fit(x_train, y_train)
y_pred_lasso = lasso_model.predict(x_test)
lasso_model_mse = mean_squared_error(y_test, y_pred_lasso)
print(f'Mean Squared Error (lasso Regression): {lasso_model_mse}')

elasticnet_model = ElasticNet(alpha=1.0, l1_ratio=0.5)
elasticnet_model.fit(x_train, y_train)
y_pred_elasticnet = elasticnet_model.predict(x_test)
elasticnet_model_mse = mean_squared_error(y_test, y_pred_elasticnet)
print(f'Mean Squared Error (ElasticNet Regression): {elasticnet_model_mse}')

decision_tree_model = DecisionTreeRegressor(max_depth=None, random_state=42)
decision_tree_model.fit(x_train, y_train)
y_pred_decision_tree = decision_tree_model.predict(x_test)
decision_tree_model_mse = mean_squared_error(y_test, y_pred_decision_tree)
print(f'Mean Squared Error (SVR): {decision_tree_model_mse}')

import pickle

filename = "XGboost.pkl"
pickle.dump(xgb_model, open(filename, "wb"))


data.head(5)



